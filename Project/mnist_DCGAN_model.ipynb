{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SOS7QLXSGTG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# example of a dcgan on mnist\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot\n",
        "import os\n",
        "\n",
        "\n",
        "# creating the standalone discriminator model\n",
        "def make_discriminator(in_shape=(28,28,1)):\n",
        "\tmodel = Sequential()\n",
        "\t# normal\n",
        "\tmodel.add(Conv2D(56, (3,3), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample\n",
        "\tmodel.add(Conv2D(112, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample\n",
        "\t# model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\t# model.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample\n",
        "\tmodel.add(Conv2D(224, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# classifier\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\tlearning_rate = 0.0002\n",
        "\tbeta1_val = 0.5\n",
        "\topt = Adam(lr = learning_rate, beta_1 = beta1_val)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\tprint(model.summary())\n",
        "\treturn model\n",
        "\n",
        "# creating the standalone generator model\n",
        "def make_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\t# Downsample the following 2 variables by 2 if layers are added\n",
        "\th = 14\n",
        "\tw = 14\n",
        "\tc = 256\n",
        "\tnum_nodes = c*h*w\n",
        "\tmodel.add(Dense(num_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((h, w, c)))\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# Following layers can be uncommented for a deeper network, please downsample h,w by two for each layer added\n",
        "\t# model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\t# model.add(LeakyReLU(alpha=0.2))\n",
        "\t# output layer\n",
        "\tmodel.add(Conv2D(1, (3,3), activation='tanh', padding='same'))\n",
        "\tprint(model.summary())\n",
        "\treturn model\n",
        "\n",
        "\n",
        "def define_gan(generator_model, disc_model):\n",
        "\n",
        "\tdisc_model.trainable = False\n",
        "\n",
        "\tmodel = Sequential()\n",
        "\n",
        "\tmodel.add(generator_model)\n",
        "\n",
        "\tmodel.add(disc_model)\n",
        "\n",
        "\tlearning_rate = 0.0002\n",
        "\tbeta1_val = 0.5\n",
        "\topt = Adam(lr = learning_rate, beta_1 = beta1_val)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "# loading and transforming data for training\n",
        "def load_real_samples():\n",
        "\n",
        "\t(trainX,_), (_,_) = load_data()\n",
        "\n",
        "\tX = trainX.astype('float32')\n",
        "\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\treturn X\n",
        "\n",
        "# select real samples\n",
        "def create_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\n",
        "\tX = dataset[ix]\n",
        "\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "\n",
        "def gen_latent_points(latent_dim, n_samples):\n",
        "\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "\n",
        "def create_fake_samples(generator_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = gen_latent_points(latent_dim, n_samples)\n",
        "\n",
        "\tX = generator_model.predict(x_input)\n",
        "\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# function to save generated images after each epoch\n",
        "def save_plot(examples, epoch, n=7, output_dir='generated_images'):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    examples = (examples + 1) / 2.0\n",
        "\n",
        "    for i in range(n * n):\n",
        "        grayscale_image = examples[i]\n",
        "\n",
        "        pyplot.subplot(n, n, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(grayscale_image, cmap='gray')  # Use 'gray' colormap for grayscale\n",
        "\n",
        "    filename = os.path.join(output_dir, 'generated_images%03d.png' % (epoch + 1))\n",
        "    pyplot.savefig(filename)\n",
        "    pyplot.close()\n",
        "\n",
        "# function to output the performance of the model and save the model after each epoch\n",
        "def print_performance(epoch, generator_model, disc_model, dataset, latent_dim, n_samples=150,output_dir='generatedisc_models'):\n",
        "\tos.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\tX_real, y_real = create_real_samples(dataset, n_samples)\n",
        "\n",
        "\t_, real_acc = disc_model.evaluate(X_real, y_real, verbose=0)\n",
        "\n",
        "\tx_fake, y_fake = create_fake_samples(generator_model, latent_dim, n_samples)\n",
        "\n",
        "\t_, fake_acc = disc_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (real_acc*100, fake_acc*100))\n",
        "\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\n",
        "\tfilename = os.path.join(output_dir, 'generated_model%03d' % (epoch + 1))\n",
        "\tgenerator_model.save(filename)\n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(generator_model, disc_model, gan_model, dataset, latent_dim, num_epochs, batch_size):\n",
        "\tnum_of_batches = int(dataset.shape[0] / batch_size)\n",
        "\thalf_batch = int(batch_size / 2)\n",
        "\n",
        "\tfor i in range(num_epochs):\n",
        "\n",
        "\t\tfor j in range(num_of_batches):\n",
        "\n",
        "\t\t\tX_real, y_real = create_real_samples(dataset, half_batch)\n",
        "\n",
        "\t\t\td_loss1, _ = disc_model.train_on_batch(X_real, y_real)\n",
        "\n",
        "\t\t\tX_fake, y_fake = create_fake_samples(generator_model, latent_dim, half_batch)\n",
        "\n",
        "\t\t\td_loss2, _ = disc_model.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "\t\t\tX_gan = gen_latent_points(latent_dim, batch_size)\n",
        "\n",
        "\t\t\ty_gan = ones((batch_size, 1))\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "\t\t\t\t(i+1, j+1, num_of_batches, d_loss1, d_loss2, g_loss))\n",
        "\n",
        "\t\tprint_performance(i, generator_model, disc_model, dataset, latent_dim)\n",
        "\n",
        "\n",
        "latent_dim = 100\n",
        "disc_model = make_discriminator()\n",
        "generator_model = make_generator(latent_dim)\n",
        "gan_model = define_gan(generator_model, disc_model)\n",
        "dataset = load_real_samples()\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "train(generator_model, disc_model, gan_model, dataset, latent_dim, num_epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of loading the generator model and generating images\n",
        "from keras.models import load_model\n",
        "from numpy.random import randn\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# plot the generated images\n",
        "def create_plot(examples, n):\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(examples[i, :, :])\n",
        "\tpyplot.show()\n",
        "\n",
        "# load model\n",
        "model = load_model('paste the path where model is stored')\n",
        "# generate images\n",
        "latent_points = generate_latent_points(100, 100)\n",
        "# generate images\n",
        "X = model.predict(latent_points)\n",
        "# scale from [-1,1] to [0,1]\n",
        "X = (X + 1) / 2.0\n",
        "# plot the result\n",
        "create_plot(X, 10)"
      ],
      "metadata": {
        "id": "w0w0fGFtOjVb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}